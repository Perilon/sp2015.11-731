#!/usr/bin/env python
import argparse
import sys
import models
import heapq
from collections import namedtuple
import math

parser = argparse.ArgumentParser(description='Simple phrase based decoder.')
parser.add_argument('-i', '--input', dest='input', default='data/input', help='File containing sentences to translate (default=data/input)')
parser.add_argument('-t', '--translation-model', dest='tm', default='data/tm', help='File containing translation model (default=data/tm)')
parser.add_argument('-s', '--stack-size', dest='s', default=100, type=int, help='Maximum stack size (default=1)')
parser.add_argument('-n', '--num_sentences', dest='num_sents', default=sys.maxint, type=int, help='Number of sentences to decode (default=no limit)')
parser.add_argument('-l', '--language-model', dest='lm', default='data/lm', help='File containing ARPA-format language model (default=data/lm)')
parser.add_argument('-v', '--verbose', dest='verbose', action='store_true', default=False,  help='Verbose mode (default=off)')
opts = parser.parse_args()

tm = models.TM(opts.tm, sys.maxint)
lm = models.LM(opts.lm)
sys.stderr.write('Decoding %s...\n' % (opts.input,))
input_sents = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]

def future_cost_table(f):
    def max_tm(source):
        max_t = -sys.maxint - 1
        if source not in tm: return max_t
        for phrase in tm[source]:
            score = phrase.logprob
            lm_state = ()
            for word in phrase.english.split():
                (lm_state, word_logprob) = lm.score(lm_state, word)
                score += word_logprob
            if score > max_t: max_t = score
        return max_t

    cost = [[0 for _ in f] for _ in f]
    for i in range(0, len(f)):
        for j in range(len(f)-i):
            if i==0:
                cost[j][j+i] = max_tm(f[j:j+i+1])
            else:
                max_lp = max_tm(f[j:j+i+1])
                for k in range(j, j+i):
                    k_cost = cost[j][k] + cost[k+1][j+i]
                    if k_cost > max_lp: max_lp = k_cost
                cost[j][j+i] = max_lp
    return cost

#cost = future_cost_table(tuple('los auspicios de'.split()))
#print cost


hypothesis = namedtuple('hypothesis', 'logprob, lm_state, predecessor, phrase, fcost')
for sent in input_sents:

    #print "sent =", sent
	# The following code implements a DP monotone decoding
	# algorithm (one that doesn't permute the target phrases).
	# Hence all hypotheses in stacks[i] represent translations of 
	# the first i words of the input sentence.
	# HINT: Generalize this so that stacks[i] contains translations
	# of any i words (remember to keep track of which words those
	# are, and to estimate future costs)

    split_possibilities = []
    english_candidates = []
    sentence_halves = []


    for x in range(len(sent)-2):
        split_possibilities.append([])
        sentence_halves.append([])
    

##    if len(sent) % 2 == 0:
##        splitpoint = len(sent)/2
##    else:
##        splitpoint = (len(sent)+1)/2
##
##    sentence_halves.append((sent[:splitpoint], sent[splitpoint:]))

    for x in range(1, len(sent)-1):
        sentence_part1 = sent[:x]
	sentence_part2 = sent[x:]
        sentence_halves[x-1].append((sentence_part1, sentence_part2))

    #print "sentence_halves =", sentence_halves

    for candidate in sentence_halves:
        for pair in candidate:
            for f in pair:
            
                fcost = future_cost_table(f)
                initial_hypothesis = hypothesis(0.0, lm.begin(), None, None, fcost[0][len(f)-1])
                uncovered = tuple(0 for _ in f)
                stacks = [{} for _ in f] + [{}]
                stacks[0][uncovered] = initial_hypothesis
                for m, stack in enumerate(stacks[:-1]):
                    # extend the top s hypotheses in the current stack
                    for cov, h in heapq.nlargest(opts.s, stack.iteritems(), key=lambda (c, h): h.logprob + h.fcost): # prune
                        for i in range(min(len(cov), m+8)):
                            if cov[i] == 1: continue
                            for j in xrange(i+1, len(f)+1):
                                if sum(cov[i:j]) > 0: continue
                                if f[i:j] in tm:
                                    covered = [0 for _ in f]
                                    start = 0
                                    future = 0.0
                                    n = 0
                                    for k in range(len(f)):
                                        if cov[k]==1 or (k >= i and k < j):
                                            covered[k] = 1
                                            n += 1
                                            if start < k: future += fcost[start][k-1]
                                            start = k + 1
                                    if start < len(f): future += fcost[start][len(f)-1]
                                    covered = tuple(covered)
                                    for phrase in tm[f[i:j]]:
                                        logprob = h.logprob + phrase.logprob
                                        lm_state = h.lm_state
                                        for word in phrase.english.split():
                                            (lm_state, word_logprob) = lm.score(lm_state, word)
                                            logprob += word_logprob
                                        logprob += lm.end(lm_state) if j == len(f) else 0.0
                                        new_hypothesis = hypothesis(logprob, lm_state, h, phrase, future)
                                                          
                                        if covered not in stacks[n] or stacks[n][covered].logprob < logprob: # second case is recombination
                                            stacks[n][covered] = new_hypothesis

                    # find best translation by looking at the best scoring hypothesis
                    # on the last stack
                    #for stack in stacks:
                      #for cov, hyp in stack.items():
                            #sys.stderr.write('{} {} {} {} {}\n'.format(cov, hyp.logprob+hyp.fcost, hyp.logprob, hyp.fcost, hyp.phrase))
                if len(stacks[-1]) > 0:
                    winner = max(stacks[-1].itervalues(), key=lambda h: h.logprob)
                #else:
                    #sys.stderr.write('error: no output\n')
                    #break
                def extract_english_recursive(h):
                    return '' if h.predecessor is None else '%s%s ' % (extract_english_recursive(h.predecessor), h.phrase.english)
                #print extract_english_recursive(winner)
                
                split_possibilities[  sentence_halves.index(candidate)   ].append(extract_english_recursive(winner))
                #print "split_possibilities =", split_possibilities

                if opts.verbose:
                    def extract_tm_logprob(h):
                        return 0.0 if h.predecessor is None else h.phrase.logprob + extract_tm_logprob(h.predecessor)
                    tm_logprob = extract_tm_logprob(winner)
                    sys.stderr.write('LM = %f, TM = %f, Total = %f\n' % 
                        (winner.logprob - tm_logprob, tm_logprob, winner.logprob))

    if [] in split_possibilities:
        split_possibilities.remove([])

    for item in split_possibilities:
	#print "item =", item
        #print "item[0] =", item[0]
        #print "item[1] =", item[1], "\n"
        english_candidates.append(item[0] + item[1])
    #print "english_candidates =", english_candidates

    #english_candidates.append((input_sents.index(sent), split_possibilities_joined))

    #print "sent =", sent

#-------------------------------------------------------------------------------------------------------------------------------------------


    # Three little utility functions:
    def coverage(sequence):
        # Generate a coverage for a sequence of indexes #
        # You can do things like:
        #   c1 | c2 to "add" coverages
        #   c1 & c2 will return 0 if c1 and c2 do NOT overlap
        #   c1 & c2 will be != 0 if c1 and c2 DO overlap
        return reduce(lambda x,y: x|y, map(lambda i: long(1) << i, sequence), 0)

    def coverage2str(c, n, on='o', off='.'):
        # Generate a length-n string representation of coverage c #
        return '' if n==0 else (on if c&1==1 else off) + coverage2str(c>>1, n-1, on, off)

    def logadd(x,y):
        # Addition in logspace: if x=log(a) and y=log(b), return log(a+b) #
        return x + math.log(1 + math.exp(y-x)) if y < x else y + math.log(1 + math.exp(x-y))

    spanish_sents = [sent for x in range(len(english_candidates))]
    english_sents = [tuple(line.strip().split()) for line in english_candidates]

    total_logprob = 0.0
    unaligned_sentences = 0

    best_score = 100000
    best_sentence_num = 0

    for sent_num, (f, e) in enumerate(zip(spanish_sents, english_sents)):
        # compute p(e) under the LM
        lm_state = lm.begin()
        lm_logprob = 0.0
        for word in e + ("</s>",):
            (lm_state, word_logprob) = lm.score(lm_state, word)
            lm_logprob += word_logprob
        total_logprob += lm_logprob

        # alignments[i] is a list of all the phrases in f that could have
        # generated phrases starting at position i in e
        alignments = [[] for _ in e]
        for fi in xrange(len(f)):
            for fj in xrange(fi+1,len(f)+1):
                if f[fi:fj] in tm:
                    for phrase in tm[f[fi:fj]]:
                        ephrase = tuple(phrase.english.split())
                        for ei in xrange(len(e)+1-len(ephrase)):
                            ej = ei+len(ephrase)
                            if ephrase == e[ei:ej]:
                                alignments[ei].append((ej, phrase.logprob, fi, fj))

        # Compute sum of probability of all possible alignments by dynamic programming.
        # To do this, recursively compute the sum over all possible alignments for each
        # each pair of English prefix (indexed by ei) and Spanish coverage (indexed by 
        # coverage v), working upwards from the base case (ei=0, v=0) [i.e. forward chaining]. 
        # The final sum is the one obtained for the pair (ei=len(e), v=range(len(f))
        chart = [{} for _ in e] + [{}]
        chart[0][0] = 0.0
        for ei, sums in enumerate(chart[:-1]):
            for v in sums:
                for ej, logprob, fi, fj in alignments[ei]:
                    if coverage(range(fi,fj)) & v == 0:
                        new_v = coverage(range(fi,fj)) | v
                        if new_v in chart[ej]:
                            chart[ej][new_v] = logadd(chart[ej][new_v], sums[v]+logprob)
                        else:
                            chart[ej][new_v] = sums[v]+logprob
        goal = coverage(range(len(f)))
        if goal in chart[len(e)]:
            total_logprob += chart[len(e)][goal]
            prob_total = lm_logprob + chart[len(e)][goal]
            #print "best_score =", best_score
            #print "prob_total =", prob_total
        else:
            #sys.stderr.write("ERROR: COULD NOT ALIGN SENTENCE %d\n" % sent_num)
            unaligned_sentences += 1

        if abs(prob_total) < abs(best_score):
            best_score = prob_total
            best_sentence_num = sent_num
            #print "best_sentence_num = ", best_sentence_num

    print english_candidates[best_sentence_num]

    ##if unaligned_sentences > 0:
    ##    sys.stderr.write("ERROR: There were %d unaligned sentences! Only sentences that align under the model can be graded!\n" % unaligned_sentences)
    ##    sys.exit(1)

    ##sys.stdout.write("%f\n" % total_logprob)

