#!/usr/bin/env python
from __future__ import division
import sys
import argparse
from collections import defaultdict
from utils import read_ttable

import numpy as np
import random

def dot(w, v):
	s = 0.0
	for k in set(w.keys()) & set(v.keys()):
		s += w[k] * v[k]
	return s

def removekey(d, key):
    r = dict(d)
    del r[key]
    return r

parser = argparse.ArgumentParser()
parser.add_argument('--input', '-i', default='data/sample.input')
parser.add_argument('--ttable', '-t', default='data/ttable')
args = parser.parse_args()

fo = open("data/sample.refs")
refs = fo.readlines()

translation_table = read_ttable(args.ttable)

rand_init_weights = np.random.random(4)
weights = {'log_prob_tgs': .1, "log_prob_sgt": .1, "log_lex_prob_tgs": .1, "log_lex_prob_sgt": .1}
#weights = {'log_prob_tgs': rand_init_weights[0], "log_prob_sgt": rand_init_weights[1], "log_lex_prob_tgs": rand_init_weights[2], "log_lex_prob_sgt": rand_init_weights[3]}

w1, w2, w3, w4 = weights["log_prob_tgs"], weights["log_prob_sgt"], weights["log_lex_prob_tgs"], weights["log_lex_prob_sgt"]

w = np.array([w1, w2, w3, w4])

alpha = .01
gamma = .1

#total_corpus_loss = 0
#total_gradient = 0

for iterations in range(3):
	input_line_index = -1
	total_corpus_loss = 0
	#total_gradient = 0
	for line in open(args.input):
		#print "w = ", w
		input_line_index += 1
		#print "input_line_index = ", input_line_index
		correct_czech = refs[input_line_index].decode("UTF-8").strip()
		#print "correct_czech =", correct_czech
		left_context, phrase, right_context = [part.strip() for part in line.decode('utf-8').strip().split('|||')]
		correct_weights = translation_table[phrase][correct_czech]
		#print "correct_weights = ", correct_weights
		c1, c2, c3, c4 = correct_weights["log_prob_tgs"], correct_weights["log_prob_sgt"], \
	                       correct_weights["log_lex_prob_tgs"], correct_weights["log_lex_prob_sgt"]
		y = np.array([c1, c2, c3, c4])
		#print "y = ", y

		incorrect_translations = removekey(translation_table[phrase], correct_czech)
		#print "incorrect_translations = ", incorrect_translations
		m = len(incorrect_translations)

		x = np.zeros([m, 4])

		for n, incorrect_czech_word in enumerate(incorrect_translations.keys()):
			in1, in2, in3, in4 = incorrect_translations[incorrect_czech_word]["log_prob_tgs"], incorrect_translations[incorrect_czech_word]["log_prob_sgt"], \
	incorrect_translations[incorrect_czech_word]["log_lex_prob_tgs"], incorrect_translations[incorrect_czech_word]["log_lex_prob_sgt"]
			temp_array = np.array([in1, in2, in3, in4])
			x[n] = temp_array
		#print "x = ", x
		loss_on_sentence = sum([max(0, (gamma - (np.dot((y - x[i]), w)))) for i in range(m)])
		#print "loss_on_sentence = ", loss_on_sentence
		total_corpus_loss += loss_on_sentence
		#print "total_corpus_loss = ", total_corpus_loss

		if loss_on_sentence > 0:
	       		gradient = sum([(x[i] - y) for i in range(m)]) # * (1.0/m)
			#total_gradient += gradient
			#print "gradient = ", gradient
			#print "total_gradient = ", total_gradient, "\n"
			w = np.subtract(w, (alpha * gradient))
			#print "new w = ", w, "\n"
		#else:
			#print "No loss here!\n"

	#w = w - (alpha * total_gradient)
	#print "total_gradient = ", total_gradient
	print "total corpus loss = ", total_corpus_loss, "\n---------------------------------\n"
	print "new w = ", w, "\n-----------------------------\n"

#for line in open(args.input):
#	left_context, phrase, right_context = [part.strip() for part in line.decode('utf-8').strip().split('|||')]
#	candidates = [target for target, features in sorted(translation_table[phrase].iteritems(), key=lambda (t, f): dot(f, weights), reverse=True)]
#	print ' ||| '.join(candidates).encode('utf-8')
